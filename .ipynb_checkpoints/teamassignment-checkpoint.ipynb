{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.spatial\n",
    "import os\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k teams per block (k=14 in the December 8 version of the experimental design)\n",
    "k = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether JDK is installed\n",
    "proc = subprocess.Popen(\"javac -version\", stdout=subprocess.PIPE, shell=True)\n",
    "output = proc.stdout.read()\n",
    "have_java = output[0:5].decode(\"utf-8\") == \"javac\"\n",
    "if not have_java:\n",
    "    msg = \"\"\"You do not have the Java compiler installed. The Maximally \n",
    "          Diverse Grouping Problem solver requires JDK 6 or higher. \n",
    "          Please run `sudo apt-get install openjdk-8-jdk` and then try \n",
    "          running this script again.\"\"\"\n",
    "    sys.exit(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# ################################################################################\n",
    "# # WHAT T&E HAVE PROVIDED\n",
    "# # explore T&E's sample data\n",
    "# df = pd.DataFrame.from_csv(\"sample_csv_files/sample_users_swarm_input.csv\")\n",
    "\n",
    "# #print(df.columns.values)\n",
    "# for i in range(len(df.columns)):\n",
    "#     print(df.columns[i])\n",
    "\n",
    "# print(df.languages_primary.unique())\n",
    "\n",
    "# # explore data dictionary\n",
    "# dd = pd.DataFrame.from_csv(\"CREATE_Ind.Diffs.Pilot_Data.Dictionary.csv\")\n",
    "\n",
    "# print(dd.index.values)\n",
    "\n",
    "# # this is likert scale in the data dictionary, binary in the sample data \n",
    "# print(df[\"enjoy_logic_probs\"])\n",
    "\n",
    "mturk = pd.DataFrame.from_csv(\"users_mturk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"block\", \n",
      "\"cond\", \n",
      "\"team\", \n",
      "\"requested_avatar\", \n",
      "\"team_lead\", \n",
      "\"age\", \n",
      "\"gender\", \n",
      "\"education\", \n",
      "\"college_major_1\", \n",
      "\"college_major_2\", \n",
      "\"college_minor_1\", \n",
      "\"college_minor_2\", \n",
      "\"occupation\", \n",
      "\"english_proficiency\", \n",
      "\"other_lang_proficien_1\", \n",
      "\"other_lang_proficien_1_TEXT\", \n",
      "\"other_lang_proficien_2\", \n",
      "\"other_lang_proficien_2_TEXT\", \n",
      "\"other_lang_proficien_3\", \n",
      "\"other_lang_proficien_3_TEXT\", \n",
      "\"other_lang_proficien_4\", \n",
      "\"other_lang_proficien_4_TEXT\", \n",
      "\"other_lang_proficien_5\", \n",
      "\"other_lang_proficien_5_TEXT\", \n",
      "\"other_lang_proficien_6\", \n",
      "\"other_lang_proficien_6_TEXT\", \n",
      "\"enjoy_logic_probs\", \n",
      "\"enjoy_num_probs\", \n",
      "\"expertise_math\", \n",
      "\"expertise_quant_model\", \n",
      "\"expertise_stats\", \n",
      "\"expertise_prob\", \n",
      "\"expertise_bayes_net\", \n",
      "\"expertise_programming\", \n",
      "\"expertise_exp_design\", \n",
      "\"expertise_risk_analysis\", \n",
      "\"expertise_forecasting\", \n",
      "\"expertise_dec_theory\", \n",
      "\"expertise_game_theory\", \n",
      "\"expertise_sats\", \n",
      "\"expertise_arg_map\", \n",
      "\"expertise_inf_logic\", \n",
      "\"expertise_sys_think\", \n",
      "\"expertise_image_analysis\", \n",
      "\"expertise_link_analysis\", \n",
      "\"expertise_graphic_design\", \n",
      "\"expertise_tech_writing\", \n",
      "\"prob_coher_35Acomp_1\", \n",
      "\"prob_coher_57A_1\", \n",
      "\"prob_coher_14Acomp_1\", \n",
      "\"prob_coher_60AUB_1\", \n",
      "\"prob_coher_5AUB_1\", \n",
      "\"matrix_1\", \n",
      "\"matrix_2\", \n",
      "\"matrix_3\", \n",
      "\"matrix_4\", \n",
      "\"matrix_5\", \n",
      "\"matrix_6\", \n",
      "\"matrix_7\", \n",
      "\"matrix_8\", \n",
      "\"matrix_9\", \n",
      "\"matrix_10\", \n",
      "\"matrix_11\", \n",
      "\"score_matrix\", \n",
      "\"prob_reas_1\", \n",
      "\"prob_reas_2\", \n",
      "\"prob_reas_3\", \n",
      "\"prob_reas_4\", \n",
      "\"prob_reas_5\", \n",
      "\"prob_reas_6\", \n",
      "\"prob_reas_7\", \n",
      "\"prob_reas_8\", \n",
      "\"prob_reas_9\", \n",
      "\"prob_reas_10\", \n",
      "\"prob_reas_11\", \n",
      "\"prob_reas_12\", \n",
      "\"prob_reas_13\", \n",
      "\"prob_reas_14\", \n",
      "\"prob_reas_15\", \n",
      "\"prob_reas_16\", \n",
      "\"score_prob_reas\", \n",
      "\"aomt_1\", \n",
      "\"aomt_2\", \n",
      "\"aomt_3\", \n",
      "\"aomt_4\", \n",
      "\"aomt_4_rev\", \n",
      "\"aomt_5\", \n",
      "\"aomt_5_rev\", \n",
      "\"aomt_6\", \n",
      "\"aomt_6_rev\", \n",
      "\"aomt_7\", \n",
      "\"aomt_7_rev\", \n",
      "\"aomt_8\", \n",
      "\"aomt_9\", \n",
      "\"aomt_9_rev\", \n",
      "\"aomt_10\", \n",
      "\"aomt_11\", \n",
      "\"score_aomt\", \n",
      "\"bfi_1\", \n",
      "\"bfi_2\", \n",
      "\"bfi_3\", \n",
      "\"bfi_4\", \n",
      "\"bfi_5\", \n",
      "\"bfi_6\", \n",
      "\"bfi_7\", \n",
      "\"bfi_8\", \n",
      "\"bfi_9\", \n",
      "\"bfi_10\", \n",
      "\"bfi_1_rev\", \n",
      "\"bfi_3_rev\", \n",
      "\"bfi_4_rev\", \n",
      "\"bfi_5_rev\", \n",
      "\"bfi_7_rev\", \n",
      "\"score_bfi_openness\", \n",
      "\"score_bfi_conscientiousness\", \n",
      "\"score_bfi_extraversion\", \n",
      "\"score_bfi_agreeableness\", \n",
      "\"score_bfi_neuroticism\", \n",
      "\"toa_1\", \n",
      "\"toa_2\", \n",
      "\"toa_2_rev\", \n",
      "\"toa_3\", \n",
      "\"toa_4\", \n",
      "\"toa_4_rev\", \n",
      "\"toa_5\", \n",
      "\"toa_6\", \n",
      "\"toa_6_rev\", \n",
      "\"toa_7\", \n",
      "\"toa_8\", \n",
      "\"toa_8_rev\", \n",
      "\"toa_9\", \n",
      "\"toa_10\", \n",
      "\"toa_10_rev\", \n",
      "\"toa_11\", \n",
      "\"toa_12\", \n",
      "\"toa_12_rev\", \n",
      "\"toa_13\", \n",
      "\"toa_14\", \n",
      "\"toa_14_rev\", \n",
      "\"toa_15\", \n",
      "\"toa_16\", \n",
      "\"toa_16_rev\", \n",
      "\"score_toa_novelty\", \n",
      "\"score_toa_complexity\", \n",
      "\"score_toa_insolubility\", \n",
      "\"rme_1\", \n",
      "\"rme_2\", \n",
      "\"rme_3\", \n",
      "\"rme_4\", \n",
      "\"rme_5\", \n",
      "\"rme_6\", \n",
      "\"rme_7\", \n",
      "\"rme_8\", \n",
      "\"rme_9\", \n",
      "\"rme_10\", \n",
      "\"rme_11\", \n",
      "\"rme_12\", \n",
      "\"rme_13\", \n",
      "\"rme_14\", \n",
      "\"rme_15\", \n",
      "\"rme_16\", \n",
      "\"rme_17\", \n",
      "\"rme_18\", \n",
      "\"rme_19\", \n",
      "\"rme_20\", \n",
      "\"rme_21\", \n",
      "\"rme_22\", \n",
      "\"rme_23\", \n",
      "\"rme_24\", \n",
      "\"rme_25\", \n",
      "\"rme_26\", \n",
      "\"rme_27\", \n",
      "\"rme_28\", \n",
      "\"rme_29\", \n",
      "\"rme_30\", \n",
      "\"rme_31\", \n",
      "\"rme_32\", \n",
      "\"rme_33\", \n",
      "\"rme_34\", \n",
      "\"rme_35\", \n",
      "\"rme_36\", \n",
      "\"score_rme\", \n",
      "\"prob_coher_14A_1\", \n",
      "\"prob_coher_35A_1\", \n",
      "\"prob_coher_5A_1\", \n",
      "\"prob_coher_60A_1\", \n",
      "\"prob_coher_5Acomp_1\", \n",
      "\"prob_coher_57Acomp_1\", \n",
      "\"prob_coher_60Acomp_1\", \n",
      "\"prob_coher_14B_1\", \n",
      "\"prob_coher_35B_1\", \n",
      "\"prob_coher_5B_1\", \n",
      "\"prob_coher_57B_1\", \n",
      "\"prob_coher_60B_1\", \n",
      "\"prob_coher_14AUB_1\", \n",
      "\"prob_coher_35AUB_1\", \n",
      "\"prob_coher_57AUB_1\", \n",
      "\"coh_score_4way\", \n",
      "\"coh_score_3way\", \n",
      "\"coh_score_2way\"\n"
     ]
    }
   ],
   "source": [
    "print('\"' + '\", \\n\"'.join(mturk.columns.values) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars = [\"block\", \n",
    "    \"cond\", \n",
    "#     \"team\", \n",
    "#     \"requested_avatar\", \n",
    "    \"team_lead\", \n",
    "    \"age\", \n",
    "    \"gender\", \n",
    "    \"education\", \n",
    "#     \"college_major_1\", \n",
    "#     \"college_major_2\", \n",
    "#     \"college_minor_1\", \n",
    "#     \"college_minor_2\", \n",
    "#     \"occupation\", \n",
    "    \"english_proficiency\", \n",
    "#     \"other_lang_proficien_1\", \n",
    "#     \"other_lang_proficien_1_TEXT\", \n",
    "#     \"other_lang_proficien_2\", \n",
    "#     \"other_lang_proficien_2_TEXT\", \n",
    "#     \"other_lang_proficien_3\", \n",
    "#     \"other_lang_proficien_3_TEXT\", \n",
    "#     \"other_lang_proficien_4\", \n",
    "#     \"other_lang_proficien_4_TEXT\", \n",
    "#     \"other_lang_proficien_5\", \n",
    "#     \"other_lang_proficien_5_TEXT\", \n",
    "#     \"other_lang_proficien_6\", \n",
    "#     \"other_lang_proficien_6_TEXT\", \n",
    "    \"enjoy_logic_probs\", \n",
    "    \"enjoy_num_probs\", \n",
    "    \"expertise_math\", \n",
    "    \"expertise_quant_model\", \n",
    "    \"expertise_stats\", \n",
    "    \"expertise_prob\", \n",
    "    \"expertise_bayes_net\", \n",
    "    \"expertise_programming\", \n",
    "    \"expertise_exp_design\", \n",
    "    \"expertise_risk_analysis\", \n",
    "    \"expertise_forecasting\", \n",
    "    \"expertise_dec_theory\", \n",
    "    \"expertise_game_theory\", \n",
    "    \"expertise_sats\", \n",
    "    \"expertise_arg_map\", \n",
    "    \"expertise_inf_logic\", \n",
    "    \"expertise_sys_think\", \n",
    "    \"expertise_image_analysis\", \n",
    "    \"expertise_link_analysis\", \n",
    "    \"expertise_graphic_design\", \n",
    "    \"expertise_tech_writing\", \n",
    "#     \"prob_coher_35Acomp_1\", \n",
    "#     \"prob_coher_57A_1\", \n",
    "#     \"prob_coher_14Acomp_1\", \n",
    "#     \"prob_coher_60AUB_1\", \n",
    "#     \"prob_coher_5AUB_1\", \n",
    "#     \"matrix_1\", \n",
    "#     \"matrix_2\", \n",
    "#     \"matrix_3\", \n",
    "#     \"matrix_4\", \n",
    "#     \"matrix_5\", \n",
    "#     \"matrix_6\", \n",
    "#     \"matrix_7\", \n",
    "#     \"matrix_8\", \n",
    "#     \"matrix_9\", \n",
    "#     \"matrix_10\", \n",
    "#     \"matrix_11\", \n",
    "    \"score_matrix\", # matrix reasoning test\n",
    "#     \"prob_reas_1\", \n",
    "#     \"prob_reas_2\", \n",
    "#     \"prob_reas_3\", \n",
    "#     \"prob_reas_4\", \n",
    "#     \"prob_reas_5\", \n",
    "#     \"prob_reas_6\", \n",
    "#     \"prob_reas_7\", \n",
    "#     \"prob_reas_8\", \n",
    "#     \"prob_reas_9\", \n",
    "#     \"prob_reas_10\", \n",
    "#     \"prob_reas_11\", \n",
    "#     \"prob_reas_12\", \n",
    "#     \"prob_reas_13\", \n",
    "#     \"prob_reas_14\", \n",
    "#     \"prob_reas_15\", \n",
    "#     \"prob_reas_16\", \n",
    "    \"score_prob_reas\", # probabilistic reasoning test\n",
    "#     \"aomt_1\", \n",
    "#     \"aomt_2\", \n",
    "#     \"aomt_3\", \n",
    "#     \"aomt_4\", \n",
    "#     \"aomt_4_rev\", \n",
    "#     \"aomt_5\", \n",
    "#     \"aomt_5_rev\", \n",
    "#     \"aomt_6\", \n",
    "#     \"aomt_6_rev\", \n",
    "#     \"aomt_7\", \n",
    "#     \"aomt_7_rev\", \n",
    "#     \"aomt_8\", \n",
    "#     \"aomt_9\", \n",
    "#     \"aomt_9_rev\", \n",
    "#     \"aomt_10\", \n",
    "#     \"aomt_11\", \n",
    "    \"score_aomt\", # actively open-minded thinking test\n",
    "#     \"bfi_1\", \n",
    "#     \"bfi_2\", \n",
    "#     \"bfi_3\", \n",
    "#     \"bfi_4\", \n",
    "#     \"bfi_5\", \n",
    "#     \"bfi_6\", \n",
    "#     \"bfi_7\", \n",
    "#     \"bfi_8\", \n",
    "#     \"bfi_9\", \n",
    "#     \"bfi_10\", \n",
    "#     \"bfi_1_rev\", \n",
    "#     \"bfi_3_rev\", \n",
    "#     \"bfi_4_rev\", \n",
    "#     \"bfi_5_rev\", \n",
    "#     \"bfi_7_rev\", \n",
    "    \"score_bfi_openness\", # big five personality inventory\n",
    "    \"score_bfi_conscientiousness\", \n",
    "    \"score_bfi_extraversion\", \n",
    "    \"score_bfi_agreeableness\", \n",
    "    \"score_bfi_neuroticism\", \n",
    "#     \"toa_1\", \n",
    "#     \"toa_2\", \n",
    "#     \"toa_2_rev\", \n",
    "#     \"toa_3\", \n",
    "#     \"toa_4\", \n",
    "#     \"toa_4_rev\", \n",
    "#     \"toa_5\", \n",
    "#     \"toa_6\", \n",
    "#     \"toa_6_rev\", \n",
    "#     \"toa_7\", \n",
    "#     \"toa_8\", \n",
    "#     \"toa_8_rev\", \n",
    "#     \"toa_9\", \n",
    "#     \"toa_10\", \n",
    "#     \"toa_10_rev\", \n",
    "#     \"toa_11\", \n",
    "#     \"toa_12\", \n",
    "#     \"toa_12_rev\", \n",
    "#     \"toa_13\", \n",
    "#     \"toa_14\", \n",
    "#     \"toa_14_rev\", \n",
    "#     \"toa_15\", \n",
    "#     \"toa_16\", \n",
    "#     \"toa_16_rev\", \n",
    "    \"score_toa_novelty\", # tolerance of ambiguity\n",
    "    \"score_toa_complexity\", \n",
    "    \"score_toa_insolubility\", \n",
    "#     \"rme_1\", \n",
    "#     \"rme_2\", \n",
    "#     \"rme_3\", \n",
    "#     \"rme_4\", \n",
    "#     \"rme_5\", \n",
    "#     \"rme_6\", \n",
    "#     \"rme_7\", \n",
    "#     \"rme_8\", \n",
    "#     \"rme_9\", \n",
    "#     \"rme_10\", \n",
    "#     \"rme_11\", \n",
    "#     \"rme_12\", \n",
    "#     \"rme_13\", \n",
    "#     \"rme_14\", \n",
    "#     \"rme_15\", \n",
    "#     \"rme_16\", \n",
    "#     \"rme_17\", \n",
    "#     \"rme_18\", \n",
    "#     \"rme_19\", \n",
    "#     \"rme_20\", \n",
    "#     \"rme_21\", \n",
    "#     \"rme_22\", \n",
    "#     \"rme_23\", \n",
    "#     \"rme_24\", \n",
    "#     \"rme_25\", \n",
    "#     \"rme_26\", \n",
    "#     \"rme_27\", \n",
    "#     \"rme_28\", \n",
    "#     \"rme_29\", \n",
    "#     \"rme_30\", \n",
    "#     \"rme_31\", \n",
    "#     \"rme_32\", \n",
    "#     \"rme_33\", \n",
    "#     \"rme_34\", \n",
    "#     \"rme_35\", \n",
    "#     \"rme_36\", \n",
    "    \"score_rme\", # Mind in the Eyes\n",
    "#     \"prob_coher_14A_1\", \n",
    "#     \"prob_coher_35A_1\", \n",
    "#     \"prob_coher_5A_1\", \n",
    "#     \"prob_coher_60A_1\", \n",
    "#     \"prob_coher_5Acomp_1\", \n",
    "#     \"prob_coher_57Acomp_1\", \n",
    "#     \"prob_coher_60Acomp_1\", \n",
    "#     \"prob_coher_14B_1\", \n",
    "#     \"prob_coher_35B_1\", \n",
    "#     \"prob_coher_5B_1\", \n",
    "#     \"prob_coher_57B_1\", \n",
    "#     \"prob_coher_60B_1\", \n",
    "#     \"prob_coher_14AUB_1\", \n",
    "#     \"prob_coher_35AUB_1\", \n",
    "#     \"prob_coher_57AUB_1\", \n",
    "    \"coh_score_4way\", \n",
    "    \"coh_score_3way\", \n",
    "    \"coh_score_2way\"]\n",
    "\n",
    "# omitted tests:\n",
    "# Berlin numeracy\n",
    "# Number sequences\n",
    "# Letter sequences\n",
    "# Cognitive Reflection Task\n",
    "# need for cognition\n",
    "# Social Value Orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# ################################################################################\n",
    "# # create realistic sample data\n",
    "\n",
    "# # create empty df with 700 rows\n",
    "# index = range(700)\n",
    "# newdf = pd.DataFrame(index=index, columns=dd.index.values)\n",
    "\n",
    "# # sample gender from a multinomial with 49% male, 49% female, 2% other\n",
    "# newdf[\"gender\"] = np.where(np.random.multinomial(1, [.49, .49, .02], 700))[1] + 1\n",
    "\n",
    "# # sample age\n",
    "# newdf[\"age\"] = (np.random.binomial(50, .5, (1,700)) + \\\n",
    "#                 [random.randint(7, 30) for x in range(700)])[0]\n",
    "\n",
    "# # sample education\n",
    "# # 1 = high school; 2 = some college; 3 = associate's degree; \n",
    "# # 4 = bachelor's degree; 5 = master's degree; 6 = professional degree or doctorate\n",
    "\n",
    "# # Because T&E are insisting all participants have a Bachelor's, the probability \n",
    "# # of values 1, 2 or 3 is zero.\n",
    "# # Probability of getting an advanced degree increases with age.\n",
    "# eds = []\n",
    "# for i in range(700):\n",
    "#     if newdf[\"age\"][i] <= 23:\n",
    "#         probs = [1., 0., 0.]\n",
    "#     elif newdf[\"age\"][i] <= 27:\n",
    "#         probs = [.9, .1, 0.]\n",
    "#     elif newdf[\"age\"][i] <= 35:\n",
    "#         probs = [.8, .15, .05]\n",
    "#     else:\n",
    "#         probs = [.7, .2, .1]\n",
    "#     eds.append((np.where(np.random.multinomial(1, probs, 1))[1] + 4)[0])\n",
    "\n",
    "# newdf[\"education\"] = eds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# create unrealistic sample data\n",
    "\n",
    "# draw continuous vars from a multivariate normal\n",
    "sigma = [[1., .2, .3], [.2, 1., .5], [.3, .5, 1.]]\n",
    "fakedata = np.random.multivariate_normal([0,0,0], sigma, 700)\n",
    "fakedf = pd.DataFrame(fakedata)\n",
    "\n",
    "# draw a binary var from a bernoulli\n",
    "fakedf[3] = np.random.binomial(1,.5, 700)\n",
    "\n",
    "# in this sample script we will use the name 'df' to refer to the data \n",
    "df = fakedf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance measures\n",
    "\n",
    "- Mahalanobis-based methods\n",
    "    - Intro: [Mahalanobis distance](https://en.wikipedia.org/wiki/Mahalanobis_distance) is \"a dissimilarity measure between two random vectors x and y of the same distribution\"\n",
    "    - [A generalized Mahalanobis distance for mixed data](https://people.ucalgary.ca/~adeleon/JMVA_mahalanobis.pdf)\n",
    "        - I don't think this will scale well when there are lots of discrete variables\n",
    "    - [Distance functions for categorical and mixed variables](https://www-sciencedirect-com.ezp.lib.unimelb.edu.au/science/article/pii/S0167865508000524)\n",
    "    - [Distance Functions for Categorical and Mixed Variables](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.139.5738&rep=rep1&type=pdf)\n",
    "    - [Estimating the Mahalanobis Distance from Mixed Continuous and Discrete Data](http://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2000.00394.x/abstract)\n",
    "    - [Generalization of the Mahalanobis Distance in the Mixed Case](http://www.sciencedirect.com/science/article/pii/S0047259X85710408)\n",
    "- [Chi square and categorial distance (see last few pages)](http://84.89.132.1/~michael/stanford/maeb4.pdf)\n",
    "- [Improved Heterogeneous Distance Functions](https://arxiv.org/pdf/cs/9701101.pdf)\n",
    "- [Gower similarity](https://stats.stackexchange.com/questions/15287/hierarchical-clustering-with-mixed-type-data-what-distance-similarity-to-use/15313#15313). See also [this explanation](https://dpmartin42.github.io/blogposts/r/cluster-mixed-types#calculating-distance).\n",
    "- [Clustering mixed data](http://onlinelibrary.wiley.com.ezp.lib.unimelb.edu.au/doi/10.1002/widm.33/full)\n",
    "- [Informational distances and related statistics in mixed continuous and categorical variables](https://www-sciencedirect-com.ezp.lib.unimelb.edu.au/science/article/pii/S0378375898001207)\n",
    "- [Jaccard, simple matching, normalized ranks, etc.](https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v4.2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "(700, 700)\n",
      "2.0\n",
      "(700, 700)\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "################################################################################\n",
    "# DISTANCE FUNCTION\n",
    "# TODO:\n",
    "# create distance function that takes a colname (or index? Or list of colnames \n",
    "# that are being treated similarly?), weight, and distance type, and outputs the\n",
    "# component of Gower Distance from that column.\n",
    "# The continuous part must be able to range-normalize AND deal with outliers. \n",
    "# Could write one function per distance type.\n",
    "\n",
    "# some messing around to test variaous things:\n",
    "\n",
    "# get manhattan distance for just one column. Use \"loc\" to select column while retaining DF structure.\n",
    "coldist_0 = scipy.spatial.distance.pdist(fakedf.loc[:, [0]], 'cityblock')\n",
    "# normalize by range of manhattan distances\n",
    "coldist_0 = (coldist_0 - coldist_0.min()) / (coldist_0.max() - coldist_0.min())\n",
    "# check max is now 1\n",
    "print(coldist_0.max())\n",
    "# check that converting back to square form preserves shape\n",
    "print(scipy.spatial.distance.squareform(coldist_0).shape)\n",
    "# check that you can sum squareforms\n",
    "print((scipy.spatial.distance.squareform(coldist_0) + scipy.spatial.distance.squareform(coldist_0)).max())\n",
    "\n",
    "# get hamming distance for just one column. Use \"loc\" to select column while retaining DF structure.\n",
    "coldist_3 = scipy.spatial.distance.pdist(fakedf.loc[:, [3]], 'hamming')\n",
    "# check that converting back to square form preserves shape\n",
    "print(scipy.spatial.distance.squareform(coldist_3).shape)\n",
    "# check that you can sum squareforms\n",
    "print((scipy.spatial.distance.squareform(coldist_3) + scipy.spatial.distance.squareform(coldist_3)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set parameters for team assignment\n",
    "# learn number of participants from input data\n",
    "n = df.shape[0]\n",
    "\n",
    "# set the number of teams\n",
    "num_teams = 20\n",
    "\n",
    "# team size limits\n",
    "# TODO: include a test of whether the sample size is too small or too large\n",
    "lims = \" 30 37\"\n",
    "\n",
    "# where to write the file for the solver\n",
    "instance_filename = 'test_instance_manhattan.txt'\n",
    "\n",
    "# if instance file already exists, remove it\n",
    "try:\n",
    "    os.remove(instance_filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# TODO: incorporate new distance function here\n",
    "# write distances to file\n",
    "with open(instance_filename, 'a') as the_file:\n",
    "    the_file.write(str(n) + \" \" + str(num_teams) + \" ss\" + str(lims)*num_teams + \"\\n\")\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            mdist = scipy.spatial.distance.cityblock(df.loc[i], df.loc[j])\n",
    "            the_file.write(str(i) + \" \" + str(j) + \" \" + str(mdist) + \"\\n\")\n",
    "\n",
    "# run solver on instance file, write data to solver file\n",
    "import subprocess\n",
    "solver_filename = \"test_output_manhattan_2.txt\"\n",
    "bash_command = \"java -jar mdgp_jors_2011.jar SO \" + instance_filename + \" 60000 > \" + solver_filename\n",
    "subprocess.call(bash_command, shell=True)\n",
    "\n",
    "# read solution from file \n",
    "with open(solver_filename) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip() for x in content]\n",
    "\n",
    "# identify line where solution is written\n",
    "sol_index = np.where([item.startswith('Solution: [') for item in content])\n",
    "\n",
    "# turn into list of ints\n",
    "solution = [int(x) for x in content[sol_index[0][0]][11:-1].split(\", \")]\n",
    "\n",
    "# add MDGP solution to dataframe of initial data\n",
    "df[\"team\"] = solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# EVALUATION\n",
    "# for comparison, let's look at the kind of teams we get with random assignment\n",
    "random_team = [0,1,2,3,4,5,6,7,8,9,\n",
    "       10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "random_team = random_team * 35\n",
    "random.shuffle(random_team)\n",
    "df[\"random_team\"] = random_team\n",
    "\n",
    "# TODO: write a function that can take a variable (or list of similar vars) and \n",
    "# its data type, and produce a report on how much the MDGP solver improves \n",
    "# balance compared to random assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>random_team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011483</td>\n",
       "      <td>-0.007597</td>\n",
       "      <td>-0.046056</td>\n",
       "      <td>11.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001858</td>\n",
       "      <td>-0.037099</td>\n",
       "      <td>-0.031557</td>\n",
       "      <td>9.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.040524</td>\n",
       "      <td>-0.032084</td>\n",
       "      <td>9.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010373</td>\n",
       "      <td>-0.035265</td>\n",
       "      <td>-0.065056</td>\n",
       "      <td>8.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012946</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>9.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007003</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.039014</td>\n",
       "      <td>10.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.028849</td>\n",
       "      <td>-0.040247</td>\n",
       "      <td>-0.031161</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.015299</td>\n",
       "      <td>-0.024475</td>\n",
       "      <td>-0.033817</td>\n",
       "      <td>10.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004975</td>\n",
       "      <td>-0.041986</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>8.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.025450</td>\n",
       "      <td>-0.007202</td>\n",
       "      <td>-0.026807</td>\n",
       "      <td>8.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004261</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>-0.048409</td>\n",
       "      <td>8.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006264</td>\n",
       "      <td>-0.043137</td>\n",
       "      <td>-0.030972</td>\n",
       "      <td>10.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002649</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>-0.025255</td>\n",
       "      <td>9.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.022497</td>\n",
       "      <td>-0.025550</td>\n",
       "      <td>-0.056309</td>\n",
       "      <td>10.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006337</td>\n",
       "      <td>-0.028039</td>\n",
       "      <td>-0.062431</td>\n",
       "      <td>9.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.024858</td>\n",
       "      <td>-0.036900</td>\n",
       "      <td>-0.040866</td>\n",
       "      <td>10.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012019</td>\n",
       "      <td>-0.023856</td>\n",
       "      <td>-0.046040</td>\n",
       "      <td>8.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.005393</td>\n",
       "      <td>-0.031753</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>9.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.009234</td>\n",
       "      <td>-0.027442</td>\n",
       "      <td>-0.039466</td>\n",
       "      <td>9.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>-0.062686</td>\n",
       "      <td>8.864865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2  random_team\n",
       "team                                           \n",
       "0     0.011483 -0.007597 -0.046056    11.648649\n",
       "1     0.001858 -0.037099 -0.031557     9.300000\n",
       "2     0.001966 -0.040524 -0.032084     9.133333\n",
       "3     0.010373 -0.035265 -0.065056     8.081081\n",
       "4     0.012946 -0.034477 -0.037939     9.810811\n",
       "5     0.007003 -0.033455 -0.039014    10.656250\n",
       "6    -0.028849 -0.040247 -0.031161     7.900000\n",
       "7    -0.015299 -0.024475 -0.033817    10.866667\n",
       "8     0.004975 -0.041986 -0.001203     8.675676\n",
       "9     0.025450 -0.007202 -0.026807     8.972973\n",
       "10    0.004261 -0.007173 -0.048409     8.432432\n",
       "11    0.006264 -0.043137 -0.030972    10.378378\n",
       "12    0.002649 -0.005408 -0.025255     9.729730\n",
       "13    0.022497 -0.025550 -0.056309    10.108108\n",
       "14    0.006337 -0.028039 -0.062431     9.270270\n",
       "15    0.024858 -0.036900 -0.040866    10.621622\n",
       "16    0.012019 -0.023856 -0.046040     8.486486\n",
       "17   -0.005393 -0.031753 -0.023085     9.133333\n",
       "18   -0.009234 -0.027442 -0.039466     9.864865\n",
       "19    0.035350  0.012332 -0.062686     8.864865"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017686</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>0.114386</td>\n",
       "      <td>9.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.191142</td>\n",
       "      <td>-0.018082</td>\n",
       "      <td>0.198901</td>\n",
       "      <td>11.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>-0.032744</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.013375</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.249023</td>\n",
       "      <td>9.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074580</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>-0.042921</td>\n",
       "      <td>8.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.249319</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>0.177016</td>\n",
       "      <td>9.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.170155</td>\n",
       "      <td>-0.128497</td>\n",
       "      <td>-0.250099</td>\n",
       "      <td>9.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.275266</td>\n",
       "      <td>-0.068279</td>\n",
       "      <td>8.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.032023</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.167983</td>\n",
       "      <td>8.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.189774</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>-0.280804</td>\n",
       "      <td>8.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.187185</td>\n",
       "      <td>-0.154885</td>\n",
       "      <td>0.028555</td>\n",
       "      <td>9.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.066552</td>\n",
       "      <td>-0.120893</td>\n",
       "      <td>-0.057945</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.007251</td>\n",
       "      <td>-0.215281</td>\n",
       "      <td>-0.288336</td>\n",
       "      <td>10.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.030566</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.139205</td>\n",
       "      <td>10.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.268123</td>\n",
       "      <td>0.030197</td>\n",
       "      <td>-0.125094</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.065408</td>\n",
       "      <td>0.120124</td>\n",
       "      <td>0.209622</td>\n",
       "      <td>10.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.039195</td>\n",
       "      <td>-0.120329</td>\n",
       "      <td>0.112122</td>\n",
       "      <td>9.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.099450</td>\n",
       "      <td>-0.234658</td>\n",
       "      <td>-0.328904</td>\n",
       "      <td>10.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.046160</td>\n",
       "      <td>-0.218872</td>\n",
       "      <td>-0.159192</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>-0.215414</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2       team\n",
       "random_team                                         \n",
       "0           -0.017686  0.011232  0.114386   9.228571\n",
       "1           -0.191142 -0.018082  0.198901  11.257143\n",
       "2            0.159420  0.009837 -0.032744  12.000000\n",
       "3           -0.013375  0.149100  0.249023   9.914286\n",
       "4            0.074580  0.030509 -0.042921   8.714286\n",
       "5            0.249319  0.031969  0.177016   9.971429\n",
       "6           -0.170155 -0.128497 -0.250099   9.600000\n",
       "7            0.018723  0.275266 -0.068279   8.428571\n",
       "8           -0.032023  0.000095 -0.167983   8.600000\n",
       "9           -0.189774 -0.025094 -0.280804   8.457143\n",
       "10           0.187185 -0.154885  0.028555   9.171429\n",
       "11           0.066552 -0.120893 -0.057945   8.200000\n",
       "12          -0.007251 -0.215281 -0.288336  10.628571\n",
       "13           0.030566  0.015353  0.139205  10.628571\n",
       "14          -0.268123  0.030197 -0.125094  10.200000\n",
       "15          -0.065408  0.120124  0.209622  10.742857\n",
       "16           0.039195 -0.120329  0.112122   9.371429\n",
       "17           0.099450 -0.234658 -0.328904  10.228571\n",
       "18          -0.046160 -0.218872 -0.159192   8.200000\n",
       "19           0.223279  0.053587 -0.215414  10.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped2 = df.groupby(['random_team'])\n",
    "grouped2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0.090161\n",
       "1               0.079958\n",
       "2               0.076046\n",
       "random_team    34.871284\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.var().var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.029392\n",
       "1        0.044489\n",
       "2        0.060557\n",
       "team    18.863760\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped2.var().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0.000214\n",
       "1              0.000232\n",
       "2              0.000240\n",
       "random_team    0.998191\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.019761\n",
       "1       0.017133\n",
       "2       0.034255\n",
       "team    1.143038\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped2.mean().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.014644\n",
      "1    0.015226\n",
      "2    0.015486\n",
      "dtype: float64\n",
      "0    0.140573\n",
      "1    0.130892\n",
      "2    0.185081\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((grouped.mean()[[0,1,2]] - df.mean()[[0,1,2]]).std())\n",
    "print((grouped2.mean()[[0,1,2]] - df.mean()[[0,1,2]]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.104172\n",
       "1    0.116323\n",
       "2    0.083674\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((grouped.mean()[[0,1,2]] - df.mean()[[0,1,2]]).std()) / ((grouped2.mean()[[0,1,2]] - df.mean()[[0,1,2]]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
